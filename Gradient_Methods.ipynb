{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment1\n",
    "## Avinash Kori | ED15B006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# assuming function to be x**2\n",
    "def get_gradient(x):\n",
    "    return 2*x\n",
    "\n",
    "def get_value(x):\n",
    "    return np.sum(x**2)\n",
    "\n",
    "def gradient_descent_update(x, eta):\n",
    "    return x - eta*get_gradient(x)\n",
    "\n",
    "\n",
    "def gradient_descent_update_AG(x, alpha=0.5, beta=0.25):\n",
    "    eta=0.5\n",
    "    max_eta=np.inf\n",
    "    min_eta=0.\n",
    "    value = get_value(x)\n",
    "    grad  = get_gradient(x)\n",
    "    while True:\n",
    "        x_cand = x - (eta)*grad\n",
    "        f  = get_value(x_cand)\n",
    "        f1 = value - eta*alpha*np.sum(np.abs(grad)**2)\n",
    "        f2 = value - eta*beta *np.sum(np.abs(grad)**2)\n",
    "        if f<=f2 and f>=f1:\n",
    "            return x_cand\n",
    "        if f>f2:\n",
    "            max_eta = eta\n",
    "            eta = (eta+min_eta)/2.0\n",
    "        if f<f1:\n",
    "            min_eta = eta\n",
    "            eta = np.min(2.*eta, (eta+max_eta)/2.)\n",
    "            \n",
    "            \n",
    "def gradient_descent_update_FR(x):\n",
    "    eta     = 0.5 \n",
    "    thresh  = 1e-6 \n",
    "    max_eta=np.inf\n",
    "    min_eta=0.\n",
    "    \n",
    "    while True:\n",
    "        x_cand = x - eta*get_gradient(x)\n",
    "        g_diff = -1.*get_gradient(x)*get_gradient(x_cand)\n",
    "        \n",
    "        if np.sum(np.abs(g_diff)) < thresh and eta > 0:\n",
    "            return x_cand\n",
    "        \n",
    "        if  eta < eta_min:\n",
    "            min_eta = eta\n",
    "            eta = min(2.*eta, (eta+max_eta)/2.)\n",
    "        else:\n",
    "            max_eta = eta\n",
    "            eta = (eta+min_eta)/2.\n",
    "            \n",
    "            \n",
    "            \n",
    "def descent_update_AG(x, desc_dir, alpha=0.5, beta=0.25):\n",
    "    eta=1.0\n",
    "    max_eta=np.inf\n",
    "    min_eta=0.\n",
    "    value = get_value(x)\n",
    "    grad  = get_gradient(x)\n",
    "    \n",
    "    grad_component = grad.T.dot(desc_dir)\n",
    "    while True:\n",
    "        x_cand = x + eta*desc_dir\n",
    "        f  = get_value(x_cand)\n",
    "        f1 = value + eta*alpha*grad_component\n",
    "        f2 = value + eta*beta *grad_component\n",
    "        \n",
    "        if f<=f2 and f>=f1:\n",
    "            return x_cand\n",
    "        if f>f2:\n",
    "            max_eta = eta\n",
    "            eta = (eta+min_eta)/2.\n",
    "        if f<f1:\n",
    "            min_eta = eta\n",
    "            eta = min(2.*eta, (eta+max_eta)/2.)\n",
    "\n",
    "            \n",
    "def descent_update_FR(x, desc_dir):\n",
    "    eta     = 1.0 \n",
    "    thresh  = 1e-6 \n",
    "    max_eta=np.inf\n",
    "    min_eta=0.\n",
    "    \n",
    "    value = get_value(x)\n",
    "    grad  = get_gradient(x)\n",
    "    grad_component = get_gradient(x)*(desc_dir)\n",
    "\n",
    "    while True:\n",
    "        x_cand = x + eta*desc_dir\n",
    "        g_diff = get_gradient(x_cand).dot(desc_dir.T)\n",
    "        if np.sum(np.abs(g_diff)) < thresh and eta > 0:\n",
    "            return x_cand\n",
    "        \n",
    "        if  eta < min_eta:\n",
    "            min_eta = eta\n",
    "            eta = min(2.*eta, (eta+max_eta)/2.)\n",
    "        else:\n",
    "            max_eta = eta\n",
    "            eta = (eta+min_eta)/2.\n",
    "\n",
    "\n",
    "def BFGS_update(H, s, y):\n",
    "    smooth = 1e-3\n",
    "    s   = np.expand_dims(s, axis= -1)\n",
    "    y   = np.expand_dims(y, axis= -1)\n",
    "    rho = 1./(s.T.dot(y) + smooth)\n",
    "    p   = (np.eye(H.shape[0]) - rho*s.dot(y.T))\n",
    "    return p.dot(H.dot(p.T)) + rho*s.dot(s.T)\n",
    "\n",
    "\n",
    "def gradient_descent(x0, num_iter=100):\n",
    "    x = x0\n",
    "    for _ in range(num_iter):\n",
    "        x = descent_update_FR(x, np.array([-10,-10]))\n",
    "    return x\n",
    "\n",
    "\n",
    "def quasi_Newton(x0, H0, num_iter=100, eta=1):\n",
    "    xo, H = x0, H0\n",
    "    for _ in range(num_iter):\n",
    "        xn = xo - eta*H.dot(get_gradient(xo))\n",
    "        y = get_gradient(xn) - get_gradient(xo)\n",
    "        s = xn - xo\n",
    "        H = BFGS_update(H, s, y)\n",
    "        xo = xn\n",
    "    return xo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.23518089e-22,  4.23518089e-22])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gradient_descent(np.array([10, 10]))\n",
    "quasi_Newton(np.array([10, 10]), np.eye(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
